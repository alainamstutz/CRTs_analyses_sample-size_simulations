---
title: "statistical analyses cluster RCTs"
author: "A.Amstutz"
date: "2023-10-18"
output:
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
    code_folding: hide
  pdf_document:
    toc: yes
---

# Analyses of cluster randomized trials (CRTs) including stepped-wedge cluster randomized trials (SW-CRTs)
This is an (incomplete) excerpt from an Inserm France workshop, prepared and taught by the wonderful team in Tours and Bordeaux (Bruno Giraudeau, Laurent Billot, Agnès Caille and several of their PhD students).

## There are two general ways to analyse CRTs
1. On cluster level ("cluster level = unit of analysis")
This is done simply by comparing cluster level data (or aggregating individual level data on cluster level) across arms using simple tests (t-test, Wilcoxon, etc.). Recommended if total number of cluster small, i.e., below ~ 10.
2. On individual level ("individual level = unit of analysis")
This is more powerful and more flexible. And recommended when there are enough clusters.
There are two approaches:
* Using cluster-specific models, i.e., mixed-models (GLMM): Interpretation: effect if an individual moves from a control CLUSTER to intervention CLUSTER. -> conditional effect
* Using population-averaged models, i.e., Generalized estimating equations (GEE): Interpretation: effect if an individual from the target population moves from control to intervention. -> marginal effect
There is an entire literature on when/how to use both of these models, and their benefit/challenges, most use mixed-models. "GEE expert": Liz Turner (https://scholars.duke.edu/person/liz.turner/publications)
3. The same is true for SW-CRT, but more complex. In addition you need to account for time and the correlation structure is more complex. Check out: https://steppedwedgehog.blog/what-is-a-stepped-wedge-trial/

## ICC reporting
1. It is good practice to report the ICC (and its 95%CI) in the results publication of a CRT, at least for the primary outcome, better, for all outcomes. For other trialists to use it, see e.g., ICC database: https://monash-biostat.shinyapps.io/CLOUDbank/
2. It is good practice to report the ICC by arm.
3. There are several ways how to calculate the ICC, most straight-forward way is using one-way ANOVA by group

## Parallel CRT with baseline period
1. "A common enhancement of a simple parallel CRT is to add an assessment of participants’ outcomes in a baseline period (before randomisation). Even if different participants are assessed at baseline and follow-up [i.e. cross-sectional sampling], the fact that they are sampled from the same cluster allows some control for cluster differences." -> https://www.bmj.com/content/360/bmj.k1121.long 
2. This is illustratively shown in the sample size calculator: https://clusterrcts.shinyapps.io/rshinyapp/ (switch between "Parallel" and "Parallel with baseline measure") -> can yield a substantial increase in power! See last chapter below.

# Load packages
```{r load packages, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(here)
library(readr)
library(sjPlot) # for tab_model()

library(lmerTest) # GLMM for CRTs with cont outcome: cluster-specific model (conditional)
library(geepack) # GEE for CRTs: population-averaged model (marginal) incl. sandwich estimator and exchangeable correlation structure
library(ICC) # one-way ANOVA for the calculation of the ICC, using mean squares within and between clusters
library(swCRTdesign) # stepped-wedge design plot

library(pwr)

```

# Parallel CRT
We want to evaluate the impact of a 6-hours fasting period prior to extubation in mechanically ventilated intensive care patients. To this end, the AMBROISIE study has been set up. The "ambroisie.csv" database contains some of the variables collected as part of this trial. Patients are included in the study at the time of the medical decision to extubate. The primary endpoint was extubation failure (reintubation or death within 7 days of extubation). Caloric intake on the day before extubation was also recorded.
Sampling frame: cohort sampling (the same people recruited and followed up, but only assessed once, at the end)

## Variable description
1. CENTER : Center
2. PATIENT : Patient number in corresponding center
3. GROUP : Center randomization group
4. BMI : BMI
5. CALBEFORE : Caloric intake the day before extubation (kcal)
6. INTUBATIONJ7 : Reintubation before D7
7. DEATHJ7 : Death on D7
8. UNIVERSITY : University hospitals or not (stratification variable at the cluster level)

## Load data
```{r message=TRUE, warning=FALSE, include=FALSE}
df <- read_delim("ambroisie.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)
```

## Continuous outcome
```{r warning=FALSE}
# reformat
df$GROUP <- as.factor(df$GROUP)
df$CENTER <- as.factor(df$CENTER)

## Use outcome CALBEFORE: An intermediate outcome, on the causal pathway between randomisation and target outcome
# GLMM 
calintake.glmm <- lmer(CALBEFORE ~ (1|CENTER) + GROUP, data = df)
tab_model(calintake.glmm)

# GEE
calintake.gee <- geeglm(CALBEFORE ~ GROUP, id = CENTER, data = df, corstr = "exchangeable")
tab_model(calintake.gee) # same as GLMM

# GLMM, adjusted for BMI
calintake.glmm.bmi <- lmer(CALBEFORE ~ (1|CENTER) + GROUP + BMI, data = df)
# GEE, adjusted for BMI
calintake.gee.bmi <- geeglm(CALBEFORE ~ GROUP + BMI, id = CENTER, data = df, corstr = "exchangeable")

# ICC directly from GLMM model
ICC_BMI_unadj <- 158.9^2/(158.9^2+584.4^2) # but this is misleading, since conditioned on intervention!
ICC_BMI_adj <- 157.7^2/(157.7^2+579.8^2) # but this is misleading, since conditioned on intervention!
# => ICC directly from GLMM without conditioning on intervention
calintake.glmm.uncond <- lmer(CALBEFORE ~ (1|CENTER) + 1,
                   data = df)
ICC_BMI_unadj_uncond <- 210.4^2/(210.4^2+584.5^2) # but this does not provide 95%CI, and is not by group
# However, it is the same ICC as from one-way ANOVA overall
ICCest(x = CENTER, y = CALBEFORE, data = df, alpha = 0.05, CI.type = "THD") # ~ same as above, ICC ~ 0.11

# One-way ANOVA ICC by group -> Gold standard to report ICC by group
ICCest(x = CENTER, y = CALBEFORE, data = df[df$GROUP == "1: Maintaining caloric intake",], alpha = 0.05, CI.type = "THD") # ICC control group
ICCest(x = CENTER, y = CALBEFORE, data = df[df$GROUP == "2: Fasting",], alpha = 0.05, CI.type = "THD") # ICC intervention group

# ICC from GEE model
calintake.gee.uncond <- geeglm(CALBEFORE ~ 1, id = CENTER, data = df, corstr = "exchangeable")
calintake.gee.uncond # See Estimated Correlation Parameters (alpha), the same: ICC ~ 0.11 // 95%CI ?
calintake.gee.uncond.cont <- geeglm(CALBEFORE ~ 1, id = CENTER, data = df[df$GROUP == "1: Maintaining caloric intake",], corstr = "exchangeable") # ICC control group
calintake.gee.uncond.int <- geeglm(CALBEFORE ~ 1, id = CENTER, data = df[df$GROUP == "2: Fasting",], corstr = "exchangeable") # ICC intervention group

```

## Binary outcome
```{r warning=FALSE}
## binary outcome: Reintubation or death (the target trial outcome)
df <- df %>% # Create the variable outcome, which is equal to 1 for failure and 0 for success. => "Failure rate"
  mutate(outcome = case_when(INTUBATIONJ7 == 0 & DEATHJ7 == 0 ~ 0,
                             INTUBATIONJ7 == 1 | DEATHJ7 == 1 ~ 1))

# GLMM, the effect of the intervention on the failure rate
outcome.glmm <- glmer(outcome ~ (1|CENTER) + GROUP, data = df, family = "binomial")
tab_model(outcome.glmm)

# GEE, the effect of the intervention on the failure rate
outcome.gee <- geeglm(outcome ~ GROUP, id = CENTER, data = df, corstr = "exchangeable", family = "binomial")
tab_model(outcome.gee) # same result as GLMM

# GLMM, adjusted for BMI
outcome.glmm.bmi <- glmer(outcome ~ (1|CENTER) + GROUP + BMI, data = df, family = "binomial")
# GEE, adjusted for BMI
outcome.gee.bmi <- geeglm(outcome ~ GROUP + BMI, id = CENTER, data = df, corstr = "exchangeable", family = "binomial")

# Gold standard: Report one-way ANOVA ICC by group // GLMM
ICCest(x = CENTER, y = outcome, data = df[df$GROUP == "1: Maintaining caloric intake",], alpha = 0.05, CI.type = "THD")
ICCest(x = CENTER, y = outcome, data = df[df$GROUP == "2: Fasting",], alpha = 0.05, CI.type = "THD")
## overall ICC (but conditioned on the intervention!)
ICCest(x = CENTER, y = outcome, data = df, alpha = 0.05, CI.type = "THD")

# Gold standard: Report one-way ANOVA ICC by group // GEE
calintake.gee.uncond.cont <- geeglm(outcome ~ 1, id = CENTER, data = df[df$GROUP == "1: Maintaining caloric intake",], corstr = "exchangeable", family = "binomial")
calintake.gee.uncond.int <- geeglm(outcome ~ 1, id = CENTER, data = df[df$GROUP == "2: Fasting",], corstr = "exchangeable", family = "binomial")

```

# SW-CRTs
Trial publication: https://pubmed.ncbi.nlm.nih.gov/30913216/

## Variable description
1. phc_code: Eighteen primary health centre (1 to 18), CLUSTER
2. PHASE: Time Period (1=6months, 2=12months, 3=18months, 4=24months) // "VERTICAL"
3. block: 3 sequences, each includes 6 PHCs, unit of randomization // "HORIZONTAL"
4. TRT:	Treatment allocation
5. primary_event:	primary, binary, outcome (SBP<140mmHg)
6. EQUK_change:	EQUK change from baseline to endline (a secondary, cont, outcome)

## Load data
```{r message=FALSE, warning=FALSE}
df <- read_delim("SMART.csv", delim = ";", 
    escape_double = FALSE, trim_ws = TRUE)
```

## Binary outcome (primary outcome)
```{r message=FALSE, warning=FALSE}
# reformat
df$primary_event_f <- as.factor(df$primary_event)
df$TRT_f <- as.factor(df$TRT)
df$PHASE_f <- as.factor(df$PHASE)

df$phc_code <- as.factor(df$phc_code) # always a factor
df$phc_code_modif <- as.factor(df$phc_code_modif) # only used for the SWplot

df <- df %>%
  mutate(primary_event_n = case_when(primary_event == "No" ~ 0,
                             primary_event == "Yes" ~ 1))
df <- df %>%
  mutate(TRT_n = case_when(TRT == "Control" ~ 0,
                             TRT == "Intervention" ~ 1))

# SW plot
swPlot(EQUK_change, TRT_n, PHASE_f, phc_code_modif, df, by.wave=FALSE,
       combined.plot=FALSE, 
       choose.tx.pos="bottomright",
       choose.legend.pos="bottom")

# table(df$PHASE,df$TRT)
# table(df$block,df$TRT) # block = sequence = randomised. Important: Different to a parallel CRT (or individual RCT) the randomized group variable is not used in the model

# GLMM
outcome.glmm <- glmer(primary_event_f ~ (1|phc_code) + TRT_f + PHASE_f, data = df, family = "binomial")
tab_model(outcome.glmm)

# GEE - what the authors used in the publication // takes ~ 1min to converge
outcome.gee <- geeglm(primary_event_n ~ TRT_f + PHASE_f, id = phc_code, data = df, corstr = "exchangeable", family = "binomial")
tab_model(outcome.gee) # same as in publication

# Note: think about decaying correlation structure

```

# Parallel CRT with baseline period
Based on: https://www.bmj.com/content/360/bmj.k1121.long
Using data from PEBRA trial.
1. Trial publication: https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1004150
2. Trial code repo: https://github.com/alainamstutz/pebra 

## There are various ways to do it:
1. Analysis of covariance (ANCOVA): Aggregate outcomes at baseline, and adjusts each individual participant at follow-up for the baseline cluster mean
2. Constrained baseline analysis: Treat outcomes collected at baseline and follow-up as longitudinal, and to use a repeated measures analysis to estimate the effect of the intervention being switched on in one of the randomised groups on the second of these occasions, see design matrix in https://clusterrcts.shinyapps.io/rshinyapp/. Unlike a difference of differences analysis, it assumes that there is no systematic difference between the groups at baseline.

## Load data
```{r message=FALSE, warning=FALSE}
df <- readRDS("df_pebra.RData")
```

## Primary model, without baseline period
```{r}
# ITT model on primary endpoint (viral load), see publication
vs <- glmer(endpoint_reached ~ ARM + (1|USER) + DISTRICT + GENDER, data = df,
              family = "binomial")
tab_model(vs)
```

## With baseline period: Analysis of covariance
```{r message=FALSE, warning=FALSE}
# Calculate the mean cluster value of the baseline viral load
df$VL_RESULT_baseline <- as.numeric(df$VL_RESULT_baseline)
df <- df %>% # there are several baseline VL variables, to force <20 into 0 is not ideal, but best we can do.
  mutate(baseline_Vl_num = case_when(baseline_Vl_cat == "<20" ~ 0,
                                     baseline_Vl_cat == ">999" ~ VL_RESULT_baseline,
                                     baseline_Vl_cat == "20-999" ~ VL_RESULT_baseline))
cluster_mean <- df %>%
  group_by(USER) %>%
  drop_na(baseline_Vl_num) %>% 
  summarize(baseline_Vl_meanUSER = mean(baseline_Vl_num))
df <- left_join(df, cluster_mean[, c("baseline_Vl_meanUSER", "USER")], by = join_by(USER == USER))

# individual-level ANCOVA with cluster-level adjustment
vs.ancova <- glmer(endpoint_reached ~ DISTRICT + ARM + GENDER + (1|USER) + baseline_Vl_meanUSER, 
              data = df, family = "binomial")
# tab_model(vs.ancova)
# not ideal, due to cluster level aggregation of viral load categories

```

## With baseline period: Constrained baseline analysis
Two possible ways: The first approach assumes that the correlation between two people from the same cluster is the same whether they are sampled in the same period or a different period. The second approach allows the correlation to be weaker between different periods. The method is extremely flexible, is available in cohort or repeated cross section forms, and allows an analysis based on individual level data, with no aggregation needed either at baseline or at follow-up.
```{r message=FALSE, warning=FALSE}
# First, reshape dataset to mirror the design
# Duplicate the dataset
df_dup <- rep(list(df), times = 2)
df_dup <- do.call(rbind, df_dup)
# Create a new variable "time" and assign values 0 and 1 to each of the created clones, corresponding to 0=baseline and 1=follow-up
df_dup$time <- rep(0:1, each = nrow(df_dup) / 2)
# Add the baseline VL to the baseline clone, using the same definition as for the outcome
df_dup <- df_dup %>% 
  mutate(baseline_endpoint_reached = case_when(baseline_Vl_cat == "<20" ~ 1,
                                               baseline_Vl_cat == "20-999" | baseline_Vl_cat == ">999" ~ 0))
df_dup <- df_dup %>% 
  mutate(endpoint_reached = case_when(time == 0 ~ baseline_endpoint_reached,
                           TRUE ~ endpoint_reached))
# Create the treatment variable by period (=time)
df_dup <- df_dup %>% 
  mutate(treat = case_when(ARM == "interv." & time == 1 ~ 1,
                           TRUE ~ 0))
# df_dup %>%
#   select(time, USER, IND_ID, ARM, treat, endpoint_reached, baseline_endpoint_reached) %>%
#   View()

# Approach 1: constrained baseline analysis – inflexible correlation structure, assuming a random effect of cluster and a random effect of individual nested within cluster, but no random effect of time nested within cluster (this fits a model where the cluster autocorrelation is assumed to be 1).
vs.constrained.inflex <- glmer(endpoint_reached ~ time + treat + (1|USER) + DISTRICT + GENDER, data = df_dup, family = "binomial")

# Approach 2: constrained baseline analysis – flexible correlation structure, assume instead a random effect of cluster, a random effect of individual nested within cluster, and a random effect of time nested within cluster (this allows the cluster autocorrelation to be less than 1)
vs.constrained.flex <- glmer(endpoint_reached ~ time + treat + (1|USER) + (1|USER:time) + DISTRICT + GENDER, data = df_dup, family = "binomial")

# compare the three models, a) primary, b) constrained baseline inflexible, c) constrained baseline flexible
tab_model(vs) # primary model
tab_model(vs.constrained.inflex) # As with a difference of differences analysis, the treatment effect is the regression coefficient for treat
tab_model(vs.constrained.flex) # As with a difference of differences analysis, the treatment effect is the regression coefficient for treat

```

# Sample size calculation for parallel CRT with binary outcome AND baseline period AND closed cohort
##### following "Hooper et al. Sample size calculation for stepped wedge and other longitudinal cluster randomised trials. Statistics in Medicine. 2016" https://onlinelibrary.wiley.com/doi/10.1002/sim.7028 
```{r message=FALSE, warning=FALSE}
# Define the design parameters
## cluster-randomized
## parallel, 1:1, two-arm, usual care
## closed cohort
## binary outcome
## with baseline period

# Define the num. parameters
alpha <- 0.05 # alpha level
power <- 0.80 # power
p_cont <- 0.20 # Proportion of outcome in the control group
p_int <- 0.35 # Proportion of outcome in the intervention group

cluster_size <- 16  # Average cluster size, i.e. participants per cluster

icc <- 0.15  # Intra-cluster correlation coefficient; "how similar outcomes are within the same cluster"
cac <- 1 # cluster auto-correlation: A cluster autocorrelation less than 1 reflects a situation where individuals sampled from the same cluster at different times have less correlated outcomes than individuals sampled from the same cluster at the same time; "how similar outcomes are within the same cluster over time" => if closed cohort, then CAC = 1, because same individuals
iac <- 0.8 # individual auto-correlation: Individual autocorrelation refers to the correlation between repeated measurements taken from the same individual over time in a longitudinal study; r=1: Perfect positive autocorrelation — successive measurements are identical; r=0: No autocorrelation — successive measurements are independent. (of course, during usual care, without the intervention)

deff_c <- 1 + (cluster_size - 1) * icc # design effect due to cluster randomising
rcc <- ((cluster_size*icc*cac) + ((1-icc)*iac)) / (1 + ((cluster_size-1)*icc)) # the correlation between Yt1kl and Yt2kl for any k, l, t1 ≠ t2 under model (9): "The only other thing that matters to the variance of the treatment effect estimator is the correlation, r"; the correlation between outcomes at different times within the same cluster (r) is the crucial factor that affects the variance of the treatment effect estimator!
deff_r <- (1-rcc^2) # design effect due to repeated assessment


# First, calculate the sample size for an individual RCT, using pwr, two-sided (effect could go either way)
ss_ind_1arm <- pwr.2p.test(h = ES.h(p_int, p_cont), 
                           sig.level = alpha, 
                           power = power)
ss_ind <- ss_ind_1arm$n * 2
# print
cat("Total sample size individual RCT, pwr:", ss_ind)
# cat("Total sample size individual RCT, pwr:", round(ss_ind, 0))

## to compare, use formula instead of pwr package
Z_alpha_half <- qnorm(1 - alpha / 2) # translate into Z-distribution -> equals 0.975 (95% CI) 
Z_beta <- qnorm(power)
ss_ind_1arm_man <- ((Z_alpha_half + Z_beta)^2 * (p_int * (1 - p_int) + p_cont * (1 - p_cont))) / (p_int - p_cont)^2
ss_ind_man <- ss_ind_1arm_man * 2
# print
cat("Total sample size individual RCT, manual:", ss_ind_man) # total sample size


# Second, inflate for clustering, following a standard parallel 1:1 CRT without repeated measures/baseline period
ss_crt_standard <- ss_ind * deff_c
cat("Total sample size CRT, standard:", ss_crt_standard) # total sample size

n_clus_crt_standard <- ss_crt_standard / cluster_size
cat("Total N clusters CRT, standard:", n_clus_crt_standard) # total number of clusters (divide by arm or sequence/steps if SWCRT)


# Third, add the baseline period and assume a closed cohort, i.e., 1 repeated measure among the same individuals
ss_crt_b_period <- deff_r*deff_c*ss_ind # total sample size
cat("Total sample size CRT, baseline period:", ss_crt_b_period) # total sample size

n_clus_crt_b_period <- ss_crt_b_period / cluster_size
cat("Total N clusters CRT, baseline period:", n_clus_crt_b_period) # total number of clusters (divide by arm or sequence/steps if SWCRT)
```
##### the exact same results were obtained when using the online sample size calculator for CRTs, developed by Hemming et al.: https://clusterrcts.shinyapps.io/rshinyapp/ (assuming an exchangable correlation structure, i.e. CAC = 1)
